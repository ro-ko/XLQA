# XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering

[![EMNLP 2025](https://img.shields.io/badge/EMNLP-2025-blue)](https://2025.emnlp.org/)  
📄 Paper (coming soon): [EMNLP 2025 Proceedings](https://arxiv.org/abs/2508.16139))  
📁 Dataset on Hugging Face: [RO-KO/xlqa](https://huggingface.co/datasets/your-org/xlqa)  
📬 Contact: ro_keonwoo@korea.ac.kr
---

## 🔍 Overview

**XLQA** is a benchmark for evaluating open-domain QA systems in **multilingual** and **locale-aware** settings.

Key features:

- 🌍 Covers 20+ languages and locales
- 📌 Emphasizes culturally and geographically grounded knowledge
- ❌ Avoids simple translation-based QA

---

## 📚 Citation

```bibtex
@inproceedings{your2025xlqa,
  title     = {XLQA: A Benchmark for Locale-Aware Multilingual Open-Domain Question Answering},
  author    = {Keon-WuΩ Roh and Yeong-Joon Ju and Seong-Whan Lee},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2025}
}
```

---

## 🤝 Contributing

We welcome contributions for:

* New locales or languages
* Additional evaluation scripts
* Error corrections and suggestions

Open an issue or pull request!

---

## 📬 Contact

* Email: [your\_ro_keonwoo@korea.ac.kr](mailto:ro_keonwoo@korea.ac.kr)
* Issues: [Open a GitHub issue](https://github.com/ro-ko/xlqa/issues)

---

## 🧠 Acknowledgements

We thank the multilingual NLP community, annotators, and contributors who made this benchmark possible.
